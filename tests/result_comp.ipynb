{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95706b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main parameter values: pop_size=60, workers=16, max_generations=500\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "community_leiden() got an unexpected keyword argument 'resolution'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.8/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/home/espl/TAU/src/tau_community_detection/script.py\", line 44, in __init__\n    self.initialize_partition()\n  File \"/home/espl/TAU/src/tau_community_detection/script.py\", line 61, in initialize_partition\n    subsample_subpartition = subgraph.community_leiden(objective_function='modularity', resolution=RESOLUTION, weights=WEIGHTS)\nTypeError: community_leiden() got an unexpected keyword argument 'resolution'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscript\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_clustering\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Now call with weighted parameter\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m tau_comms, tau_mod \u001b[38;5;241m=\u001b[39m \u001b[43mrun_clustering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUsoskin_graph.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexample\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# This should work now\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_graph\u001b[39m(path):\n\u001b[1;32m     19\u001b[0m     nx_graph \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mread_adjlist(path)\n",
      "File \u001b[0;32m~/TAU/src/tau_community_detection/script.py:440\u001b[0m, in \u001b[0;36mrun_clustering\u001b[0;34m(graph, graph_name, size, max_generations, workers, seed, resolution, weighted)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMain parameter values: pop_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPOPULATION_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, workers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_WORKERS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, max_generations=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_GENERATIONS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     best_partition, mod_history \u001b[38;5;241m=\u001b[39m \u001b[43mfind_partition\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTAU_partition_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, best_partition\u001b[38;5;241m.\u001b[39mmembership)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest modularity:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_partition\u001b[38;5;241m.\u001b[39mfitness)\n",
      "File \u001b[0;32m~/TAU/src/tau_community_detection/script.py:316\u001b[0m, in \u001b[0;36mfind_partition\u001b[0;34m()\u001b[0m\n\u001b[1;32m    313\u001b[0m cnt_convergence \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Population initialization\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m pop \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize_of_population\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPOPULATION_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m generation_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, MAX_GENERATIONS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    319\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/TAU/src/tau_community_detection/script.py:209\u001b[0m, in \u001b[0;36mcreate_population\u001b[0;34m(size_of_population)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize a population of Partitions with random sample fractions.\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m fracs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, size_of_population)\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPOOL\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfracs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mTypeError\u001b[0m: community_leiden() got an unexpected keyword argument 'resolution'"
     ]
    }
   ],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "from tau_community_detection import run_clustering\n",
    "import sys\n",
    "sys.path.append('/home/espl/TAU/src/tau_community_detection')\n",
    "from script import run_clustering\n",
    "\n",
    "# Now call with weighted parameter\n",
    "tau_comms, tau_mod = run_clustering(\n",
    "    'Usoskin_graph.csv',\n",
    "    graph_name=\"example\",\n",
    "    weighted=True  # This should work now\n",
    ")\n",
    "\n",
    "def load_graph(path):\n",
    "    nx_graph = nx.read_adjlist(path)\n",
    "    mapping = dict(zip(nx_graph.nodes(), range(nx_graph.number_of_nodes())))\n",
    "    nx_graph = nx.relabel_nodes(nx_graph, mapping)\n",
    "    ig_graph = ig.Graph(len(nx_graph), list(zip(*list(zip(*nx.to_edgelist(nx_graph)))[:2])))\n",
    "    return ig_graph\n",
    "\n",
    "def load_csv(filename):\n",
    "    \"\"\"\n",
    "    Load an edge list from a CSV file with columns: source,target[,weight]\n",
    "    Returns an igraph.Graph object (undirected).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(filename)\n",
    "    if not {\"source\", \"target\"}.issubset(df.columns):\n",
    "        raise ValueError(\"CSV must have columns: 'source','target' (optional: 'weight').\")\n",
    "    src = df[\"source\"].astype(str).tolist()\n",
    "    tgt = df[\"target\"].astype(str).tolist()\n",
    "    has_weight = \"weight\" in df.columns\n",
    "    weights = df[\"weight\"].astype(float).tolist() if has_weight else None\n",
    "\n",
    "    # Map node ids to 0-based indices (stable order)\n",
    "    nodes = pd.Index(src).append(pd.Index(tgt)).unique().tolist()\n",
    "    node_mapping = {n: i for i, n in enumerate(nodes)}\n",
    "    edges = [(node_mapping[u], node_mapping[v]) for u, v in zip(src, tgt)]\n",
    "\n",
    "    g = ig.Graph(n=len(nodes), edges=edges, directed=False)\n",
    "    if has_weight:\n",
    "        g.es[\"weight\"] = weights\n",
    "    g['original_node_ids'] = node_mapping\n",
    "    return g\n",
    "\n",
    "communities, tau_mod = run_clustering(\n",
    "    'tests/example.graph',\n",
    "    graph_name=\"Usoskin_graph\",\n",
    "    size=100,\n",
    "    max_generations=200\n",
    ")\n",
    "print(communities.shape())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
